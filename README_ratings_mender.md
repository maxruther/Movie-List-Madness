# Improving the Critical Review Data - Subproject #3
## *Reporting and remapping missing review scores, as well as adding a new reviewer*

In this third phase of my project, I remedy and supplement the review score data just retrieved from *OMDb* (as was done in the [phase preceding.](/README_omdb_builder.md)) These processes, which comprise the *critic_ratings.RatingsTableMender* package, largely involve remapping missing values and joining in review scores from an additional external source.

<br></br>
<center><img src="Presentation/pics for quick overview/3 - cr table before after.png" width="80%" height="20%"/> </center>
<br></br>

To describe it in short, this area of my movie project makes the following two improvements to the integrity of my critical review score data:
1) Missing review score values are programmatically reported and later remapped, given manually amended mappings. This is done for every reviewer.
2) Scores are added to the table for an additional review site, *RogerEbert*.

    *(These new scores are read in from a local csv file. A [scraper](/critic_ratings/scrapers/ebert_scrape_by_googling.py) or [two](/critic_ratings/scrapers/ebert_scrape_by_inf_scroll.py) for these scores are still in development. Scrapers for several other sites are already [complete.](/README_scraping_reviews.md))*
        

## A Walkthrough of these processes

Please see my corresponding notebook document ([html](/Analysis/Jupyter%20HTMLs/1%20-%20Fixing%20the%20CR%20Table.html)  or [ipynb](/Analysis/1%20-%20Fixing%20the%20CR%20Table.ipynb)) if you would like a presentable walkthrough of this subproject's processes.

This walkthrough document features code snippets that mainly provide this subproject's functionality. It also contextualizes this subproject with motivations and chronology, in written elements.

If you are interested in further detail, please read on to the next section.


## Closer details on these processes

As mentioned above, this package's processes improve on the review score data, by both filling in erroneously missing values and adding another external review source. This review score data resides in the *critic_ratings* table of my local MySQL database, which was created at the conclusion of the preceding project phase.

### Missing Values: Reporting and Remapping

First, all this table's contents are queried. Next, the missing review score values are handled, for each reviewer. This is done by applying reviewer-specific mappings to the *critic_ratings* copy in memory (the query result) then using that copy to overwrite the original table in MySQL.

These mappings are originally generated by this package's reporting methods (found in *_reporting.py*.) For each reviewer, these methods query the films that are missing review scores, then print them in the formatting of a Python dictionary literal.

<br></br>
<center><img src="Presentation/pics for quick overview/3 - reported missing mc scores.png" width="30%" height="20%"/> </center>
<br></br>

These dictionary literals are printed to initially lack values, allowing for straightforward completion by the user through manual entry. Once complete, this literal must be pasted into the dedicated mapping file, *_reviewer_mappings.py*, in order to be applied.

<br></br>
<center><img src="Presentation/pics for quick overview/3 - making additions to maps.png" width="40%" height="20%"/> </center>
<br></br>

<!-- <br></br> -->
<center><img src="Presentation/pics for quick overview/3 - reporting - after mapping adds.png" width="40%" height="20%"/> </center>
<br></br>

When each mapping is applied, only missing values will be remapped. So in the event that a later data pull from *OMDb* no longer lacks a mapped review score, the newly-existing value won't be overwritten by the mapping.

### Adding a New Reviewer: RogerEbert

The process for the second task of improving the review score data starts as that of the first did, by querying the full contents of the *critic_ratings* table. It then reads in *RogerEbert* ratings from a local file. This file containing nearly 250 ratings was unfortunately one that I created manually, not programmatically.

Those *RogerEbert* ratings are then joined to the *critic_ratings* table in memory on the film attributes *Title* and *Year*. Just as in the previous process, this updated table is written over its original residing in the MySQL database.

<br></br>
<center><img src="Presentation/pics for quick overview/3 - adding rogerebert scores.png" width="40%" height="20%"/> </center>
<br></br>


## Motivations
### *Addressing concerns with the* OMDb *review scores*

In this third phase of my project, I hone in on this *OMDb* data's aggregate review scores. My focus shifted to these attributes because I suspected that they would be strongly predictive of my own ratings, and such prediction was a goal of mine.

After some examination of these review score attributes, I determined that this data was sparser than I'd like, in two regards:
1) Some review scores reported as missing in the *OMDb* data did in fact exist, at the reviewer's website.
2) I wanted to add one more source of review scores (for now) by collecting and joining in data from *RogerEbert*, a publication I favor.

It felt important to address these concerns and so mitigate the data's sparsity, especially given that the sample (formed of my own watches) was already so small- then about 200 films. Moreover, in later analyses of this review data, I found it comforting to consider that I had so personally invested in the subject's integrity.


## Future Work

I intend to revisit this area of my project to make the following enhancements:
- Fix the webscraper I built for *RogerEbert* ratings by incorporating Selenium. (My existing scraper, *ebert_scrape_by_googling.py*, gets blocked after retrieving 25-40 ratings.)
    - Further improve this scraper by having it reference the existing ratings file before scraping, so that it skips scraping any films that have already been scraped.
- Try joining in additional reviewers, specifically those of my LetterBoxd friends, whose ratings I have successfully scraped with *lb_scrape_friend_reacts.py*. 

This last webscraper and others are the focus of this project's next phase...


# Next up: [Scraping for more reviews](/README_scraping_reviews.md)

In the next phase, I code webscrapers to gather review scores, both from LetterBoxd friends and from those individual publications that form Metacritic's critical aggregate, the *Metascore*.

